{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a39d1d",
   "metadata": {},
   "source": [
    "# Función que hace stemming de las palabras del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26622269",
   "metadata": {},
   "source": [
    "Realizaremos stemming de las sinopsis limpiadas para quedarnos con la raíz de las palabras ya que es la única parte de la palabra que contiene la información útil. Para este procedimiento utilizaremos la clase SnowballStemmer de la librería NLTK debido a que es el algoritmo de Stemmer más eficaz para un corpus en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58939d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     /home/moffinguer/nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('snowball_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d5b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(input_file, output_file):\n",
    "    \n",
    "    # Crear el stemmer en español\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "    # Abrir el archivo de entrada y el archivo de salida\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"sinopsis\\tgenero\\n\")  # Escribir la cabecera en el archivo de salida\n",
    "\n",
    "        for line in lines[1:]:\n",
    "            synopsis, genre = line.strip().split('\\t')\n",
    "\n",
    "            # Tokenizar la sinopsis en palabras\n",
    "            tokens = nltk.word_tokenize(synopsis)\n",
    "\n",
    "            # Aplicar stemming a cada palabra de la sinopsis\n",
    "            stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "            # Unir los tokens procesados en una sola cadena\n",
    "            processed_text = ' '.join(stemmed_tokens)\n",
    "\n",
    "            # Escribir la sinopsis procesada y el género en el archivo de salida\n",
    "            file.write(f\"{processed_text}\\t{genre}\\n\")\n",
    "\n",
    "    print(\"Stemming aplicado. El archivo procesado se guardó en:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67846660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming aplicado. El archivo procesado se guardó en: ../data/stemming_data.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = '../data/tokenize_data.txt'\n",
    "output_file = '../data/stemming_data.txt'\n",
    "apply_stemming(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e794e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
